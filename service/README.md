# Demo 开发文档摘要

V 1.0.20220125

## 架构

### Encoder

1. 首先，第三方软件进行推流。
2. 服务端拿到第三方流，对流的每帧进行计算（自然是多线程的处理与计算）：
   - 首先，计算是不是与上一帧近似（近似算法是什么？阈值又该如何设置？）（这里会保存上一帧的 `base64`）
   - 再次，如果不近似，则将**该帧送入** Encoder 进行编码（同时送入一个可自定义的 **7** 位的 `Char` 用于隐写编码），Encoder 应返回**残差图与原图相加完成的结果图**。然后，将该处理完毕的帧的 `base64` 编码存入当前线程的一个全局变量中。如若近似，跳过 Encoder ，直接将上一帧的处理后的图作为结果图送入视频流。
   - 接着，完成编码后，在另一新线程中操作数据库，将当前用户的 ID、IP、分钟级时间戳等信息存入数据库。
   - 最后，进行推流。（这里需要注意了：H.264 编码 以及 码率 会影响图像传输时导致的高频信息丢失；这里需要设置一个合适的码率，码率越高丢失越少，但是对应的视频流的延迟会增加。）
3. 客户端拿到视频流，前端显示视频流画面。

### Decoder

1. 目前限制用户只能传一张图片。用户上传图片后，可以选择直接上传到服务器并解码，或者进入**标定环节**对图片进行标定。
2. 标定环节说明：所谓标定，即要求用户按照**从左上角起**，**按逆时针顺序**，在上传的图片上标点，**一共标四个点**，四点可以连成一个矩形，这个矩形框住的就是最后要解码的图像。用户要么不标点，要么就要标 4 个点，否则无法继续上传。标定完成后点击上传按钮，后端拿到标定的四个点的各自相对于上传图像的比例坐标，以及上传的**原**图像的 `base64` 编码，然后进行透视变换。（这里意味着前端不处理图像，仅仅回传附加信息，图像处理全部由后端负责）。
3. 上传完成后，如果包含了附加坐标信息，就进行透视变换，然后送 Decoder 解码；否则直接将图像送入 Decoder 进行解码。解码获取到 ID 和分钟级时间戳后，查询数据库，获得相应 ID 的拓展信息，返回给前端显示。（这里没有做多线程，除非做一个排队机制：返回给用户一个提取码，然后后端根据队列进行解码，用户根据这个提取码可以得到最后的拓展信息。此外，为了提高容错率，查询数据库时，可以额外指定一个时间误差值，以分钟为单位；根据解码后的信息中的分钟级时间戳进行计算，查询一个时间范围内的所有记录，而非一个特定时间）



## Demo 内容

> 由于 RTMP 协议的延迟问题，这里摒弃了 Java。

 - **第三方推流**
   
   - [x] 采用 OBS 进行推流（存在 1s 左右延迟；之后考虑直接命令行推流，优化推流参数来降低延迟）。
   
 - **服务端（采用 Flask 框架）**
   
   - [x] 自定义 ID 接口。
   - [x] 拉流：第三方视频流。
   - [ ] 动态帧率的判定。
   - [ ] 帧处理。（需要训练好的 Encoder 模型）
   - [x] 根据拉流活动情况将拓展信息持久化。
   - [x] 推流：`FFmpeg` 推流。
   - [x] 图像上传接口。
   - [x] 透视变换。
   - [x] 查询数据库并返回信息。
   
 - **客户端（采用 Vue.js）**
   
   - [x] `flv` 播放器。
   - [x] ID 修改框与逻辑。
   - [x] 上传逻辑。
   - [x] 标定逻辑。
   - [x] 返回的信息处理逻辑。
   - [x] 静态资源、功能函数以及预留接口的封装。
   - [x] 布局与样式设计。
   
 - **流媒体服务器（Nginx + nginx-http-flv-module）**
   - [x] rtmp 协议的设置。
   
   
## 目录说明

- `backend`：

  - `src`：

    - `model`：存放训练完毕的模型，并暴露为一个接口，形如：

      ```python
      # frame 为处理的帧，encoder 为编码器模型
      frame = encoder(frame, **kwargs)
      ```

      - 已包含一个 `encoderLive` 流媒体处理的封装，里面还需填补上述 SDK 调用接口。

    - `utils.py`：工具与枚举类。

    - `properties.py`：配置类（一些配置信息在这里写）。
    
    - `main.py`：主函数类。
    
    - `db.sqlite3`：测试数据库。

- `frontend`：

  - `public`：入口网页，仅 `index.html` 需要修改。
  - `src`：
    - `assets`：静态资源。
      - `fonts`：字体（内含两种字体，封装采用了 bilibili 的方案）
      - `res.js`：资源文件，内含一个默认的 比例坐标。
    - `components`：组件。（本项目未做对应的组件封装，这个文件夹为空）
    - `router`：路由。（前端路由导航）
    - `store`：Vuex。（本项目不使用）
    - `styles`：样式。（字体样式和初始化样式）
    - `utils`：工具。
      - `http.js`：`axios` 路由封装。（发到后端什么路由，用什么 HTTP 方法之类的）
      - `others.js`：其他工具。（实际用到的就一个 文件转 `base64` ）
    - `views`：视图。
      - `404.vue`：找不到。
      - `Decoder.vue`：解码器演示。
      - `Encoder.vue`：编码器演示。
      - `Frame.vue`：整体网页框架。
      - `Main.vue`：主页。
    - `App.vue`：入口文件。
    - `main.js`：配置文件。



## 部署

1. FFmpeg

   - 在 www.ffmpeg.org 下载编译完成的 Windows 版本的即可。
   - 配置环境变量。

2. Nginx

   Nginx 在本机上运行为两个实例，一个用来做 OBS 的推流服务，另一个用来做 服务端 的推流服务。

   这里提供一个编译完成的带有 flv 模块的版本，需要修改的就是 `Nginx` 根目录下 `conf` 文件夹下的 `nginx.conf` 中：

   ```bash
       server {
           listen 1935; # 运行端口，一个是 1935，另一个是 2935
   
           chunk_size 4000;
           application live {
               live on;
   			gop_cache on;
   			hls on;
               hls_path D:/nginx-rtmp/html/hls; # 这里改为 Nginx 对应 绝对路径 下的 html/hls，两个 Nginx 都要改
   ```

   - 双击运行 `nginx.exe` 即可作为后台服务启动。

3. Python 环境

   ```bash
   pip install flask opencv-python numpy sqlite3
   ```

4. 前端环境

   - 安装 Node.js （选上添加到环境变量）。

   - 在 `frontend` 下运行：

     ```bash
  npm install
     ```

4. 运行步骤：

   - 启动两个 Nginx；（建议通过命令行启动，可以看到运行时会出的错（比如端口占用））。

   - 启动第三方推流；

     > 默认（这些可以在 `properties.py` 里面改）：
     >
     > OBS 推流到 rtmp://127.0.0.1:2953/live ，但密钥写 test
     >
     > 然后拉这个 OBS 流时，URL 为 rtmp://127.0.0.1:2953/live/test
     >
     > 
     >
     > 服务端将处理后的视频推流到 rtmp://127.0.0.1:1953/live/test
   
   - 保证 `db.sqlite3` 在 `backend/src` 下，否则需要更改 `properties.py` 中数据库的位置。
   
   - 在项目目录下：
   
     ```bash
     # 启动后端
     cd backend/src
     python main.py
     ```
     
     ```bash
     # 启动前端
     cd frontend
     npm run serve
     ```
     
   - 访问 http://127.0.0.1:8080